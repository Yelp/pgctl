import errno
import functools
import os
import stat
import subprocess
import typing
from collections import namedtuple
from contextlib import contextmanager

from cached_property import cached_property
from frozendict import frozendict

from .daemontools import svc
from .daemontools import SvStat
from .daemontools import svstat
from .debug import debug
from .debug import trace
from .errors import Impossible
from .errors import NoSuchService
from .errors import NotReady
from .errors import reraise
from .functions import bestrelpath
from .functions import exec_
from .functions import logger_preexec
from .functions import ps
from .functions import show_runaway_processes
from .functions import supervisor_preexec
from .functions import symlink_if_necessary
from .functions import terminate_processes
from .subprocess import Popen
from pgctl import environment_tracing
from pgctl import fuser


LOG_RUN_HEADER = \
    """#!/bin/bash
#####################################################################
# This file is automatically generated by pgctl.
# You should *NOT* modify this file or check it in to source control.
#####################################################################\n
"""


def flock(path):
    """attempt to show the user a better message on failure, and handle the race condition"""
    def handle_race(path):
        show_runaway_processes(path)
        if handle_race.limit > 0:
            handle_race.limit -= 1
        else:
            reraise(Impossible('lock is held, but not by any process, ten times'))
    handle_race.limit = 10

    from .flock import flock
    return flock(path, on_fail=handle_race)


class Service(namedtuple('Service', ['path', 'scratch_dir', 'default_timeout', 'environment_tracing_enabled'])):

    # TODO-TEST: regression: these cached-properties are actually cached
    __exists = False

    def __str__(self):
        return self.name

    def supervised(self):
        # TODO-TEST: bring service up, clean symlink, run Service.supervised()
        self.ensure_exists()
        from .daemontools import svok
        return svok(self.path.strpath)

    def svstat(self):
        self.ensure_exists()
        return self._svstat_path(self.path)

    def _svstat_path(self, path):
        with path.dirpath().as_cwd():
            result = svstat(path.basename)
        if not self.notification_fd.exists():
            # services without notification need to be considered ready sometimes
            if (
                    # an 'up' service is always ready
                    (result.state == 'up' and result.process is None) or
                    # restarting continuously and successfully can/should be considered 'ready'
                    (result.process == 'starting' and result.exitcode == 0 and result.seconds == 0)
            ):
                result = result._replace(state='ready')
        trace('PARSED: %s', result)
        return result

    @property
    def state(self):
        svstat = self.svstat()
        state = {
            key: getattr(svstat, key)
            for key in svstat._fields
        }
        if state['state'] == SvStat.UNSUPERVISED:
            # this is the expected state for down services.
            state['state'] = 'down'
        return state

    def message(self, state) -> typing.Optional[str]:
        script = self.path.join(state.strings.change + '-msg')
        if script.exists():
            proc = subprocess.run((script.strpath,), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
            output = proc.stdout.decode('utf8', errors='replace')
            if proc.returncode != 0:
                raise AssertionError(f'"{script}" exited with error code {proc.returncode} and output:\n{output}')
            return output

    @cached_property
    def ready_script(self):
        return self.path.join('ready')

    @cached_property
    def notification_fd(self):
        return self.path.join('notification-fd')

    def start(self):
        """Idempotent start of a service or group of services"""
        self.background()
        svc(('-u', self.path.join('.log').strpath))
        svc(('-u', self.path.strpath))

    def stop(self):
        """Idempotent stop of a service or group of services"""
        self.ensure_exists()
        svc(('-dx', self.path.strpath))

    def stop_logs(self):
        self.ensure_logs()
        svc(('-kx', self.path.join('.log').strpath))

    def _pids_running_from_fuser(self) -> typing.Set[int]:
        return set(fuser.fuser(self.path)) - {os.getpid()}

    def _pids_running_from_environment_tracing(self) -> typing.Set[int]:
        if self.environment_tracing_enabled:
            return environment_tracing.find_processes_with_environ(
                {
                    b'PGCTL_SERVICE': self.path.strpath.encode('utf8'),
                    b'PGCTL_SERVICE_PROCESS': b'true',
                },
            ) - {os.getpid()}
        else:
            return set()

    def processes_currently_running(self) -> typing.Set[int]:
        return self._pids_running_from_fuser() | self._pids_running_from_environment_tracing()

    def force_cleanup(self, is_stop: bool = True) -> typing.Optional[str]:
        """Forcefully stop a service (i.e., `kill -9` all processes still running."""
        return terminate_processes(self.processes_currently_running(), is_stop=is_stop)

    def __get_timeout(self, name, default):
        timeout = self.path.join(name, abs=1)
        if timeout.check():
            debug('%s exists', name)
            return float(timeout.read().strip())
        else:
            debug('%s doesn\'t exist', name)
            return float(default)

    @cached_property
    def timeout_stop(self):
        return self.__get_timeout('timeout-stop', self.default_timeout)

    @cached_property
    def timeout_ready(self):
        return self.__get_timeout('timeout-ready', self.default_timeout)

    def assert_stopped(self, with_log_running=False):
        status = self.svstat()
        if status.state != SvStat.UNSUPERVISED:
            raise NotReady('its status is ' + str(status))

        if not with_log_running and self.is_logger_running():
            raise NotReady('its status is its s6-log is still running.')

        # If we can obtain this flock at all, it means that there are no
        # subprocesses holding it. (Normally the service and its subprocesses
        # will hold this lock until they exit.)
        with self.flock():
            # Sometimes a service spawns subprocesses without inheriting the flock
            # fd; we use this special env-var-based detection to catch those.
            escaped_running_pids = self.processes_currently_running()
            if escaped_running_pids:
                raise NotReady('''\
these runaway processes did not stop:
{}
This usually means these processes are buggy.
Learn more: https://pgctl.readthedocs.org/en/latest/user/quickstart.html#writing-playground-services
'''.format(ps(escaped_running_pids)))

        # If we got here, everything is really down.
        return

    def assert_ready(self):
        status = self.svstat()
        if status.state != 'ready':
            raise NotReady('its status is ' + str(status))

    def ensure_exists(self):
        if self.__exists:
            return

        if not self.path.check(dir=True):
            raise NoSuchService("No such service: '%s'" % bestrelpath(str(self.path)))

        self._ensure_supervise_is_scratch('supervise')
        self.__exists = True

    def ensure_logs(self):
        self.ensure_exists()
        self.path.ensure_dir('logs')
        self.path.join('logs').ensure('current')

        self.path.ensure_dir('.log')
        with open(self.path.join('.log', 'run').strpath, 'w') as log_run:
            log_run.write(LOG_RUN_HEADER)
            log_run.write(
                'exec s6-log -b n5 s10485760 T {log_path}\n'.format(
                    log_path=self.path.join('logs').strpath,
                ),
            )
            log_run_stat = os.fstat(log_run.fileno())
            os.fchmod(log_run.fileno(), log_run_stat.st_mode | stat.S_IXUSR)

        self._ensure_supervise_is_scratch('.log/supervise')

    @property
    def logfile_path(self):
        return self.path.join('logs').join('current')

    def _ensure_supervise_is_scratch(self, supervise_rel_path):
        # ensure symlink {service_dir}/supervise_rel_path -> {scratch_dir}/supervise_rel_path
        # this will re-connect the service to its state descriptors if the symlinks have been deleted or moved
        supervise_in_scratch = self.scratch_dir.join(supervise_rel_path)
        supervise_in_scratch.ensure_dir()
        symlink_if_necessary(
            supervise_in_scratch,
            self.path.join(supervise_rel_path),
        )

    def ensure_directory_structure(self):
        """Ensure that the scratch directory exists and symlinks supervise.

        Due to quirks in pip and potentially other package managers, we don't
        want named FIFOs on disk inside the project repo (they'll end up in
        tarballs and other junk).

        Instead, we stick them in a scratch directory outside of the repo.
        """
        # TODO: enforce that we have the supervise lock when this is called, somehow
        self.ensure_exists()
        self.ensure_logs()
        self.path.ensure('nosetsid')  # see http://skarnet.org/software/s6/servicedir.html
        from py._error import error as pylib_error
        try:
            self.path.join('down').remove()  # pgctl doesn't support the s6 down file
        except pylib_error.ENOENT:
            pass

        if self.ready_script.exists():
            with self.notification_fd.open('w') as f:
                f.write('%i\n' % f.fileno())

    @contextmanager
    def flock(self):
        # if we already have the lock, from a parent process, use it.
        parent_service = os.environ.pop('PGCTL_SERVICE', None)
        lock = os.environ.pop('PGCTL_SERVICE_LOCK', None)
        debug('parentlock: %r', parent_service)
        if lock:
            lock = int(lock)
            if parent_service == self.path:
                debug('retrieved parent lock! %i', lock)
                try:
                    yield lock
                finally:
                    os.close(lock)
                return
            else:
                from .flock import release
                release(lock)

        with flock(self.path.strpath) as lock:
            debug('LOCK: %i', lock)
            self.ensure_directory_structure()
            with self.path.as_cwd():
                yield lock

    def background(self):
        """Run supervise(1), while ensuring it is properly symlinked."""
        if self.supervised():
            return

        with self.flock() as lock:
            log_fifo_path = self.path.join('log_pipe').strpath

            try:
                os.mkfifo(log_fifo_path)
            except OSError as e:
                if e.errno != errno.EEXIST:
                    raise

            if not self.is_logger_running():
                Popen(
                    (
                        's6-supervise',
                        self.path.join('.log').strpath,
                    ),
                    env=self.supervise_env(lock, debug=False, logs=True),
                    preexec_fn=functools.partial(
                        logger_preexec,
                        log_fifo_path,
                    ),
                    close_fds=True,
                )

            Popen(
                (
                    's6-supervise',
                    self.path.strpath,
                ),
                env=self.supervise_env(lock, debug=False),
                preexec_fn=functools.partial(
                    supervisor_preexec,
                    log_fifo_path,
                ),
            )

    def foreground(self):
        with self.flock() as lock:
            exec_(
                (str(self.path.join('run')),),
                env=self.supervise_env(lock, debug=True),
            )  # never returns

    def is_logger_running(self):
        status = self._svstat_path(self.path.join('.log'))
        return status.state != SvStat.UNSUPERVISED

    @cached_property
    def name(self):
        return self.path.basename

    def supervise_env(self, lock, debug, logs=False):
        """Returns an environment dict to use for running supervise."""
        env = dict(
            os.environ,
            PGCTL_SCRATCH=str(self.scratch_dir),
            # TODO-TEST: assert this env var is available and correct
            PGCTL_SERVICE=str(self.path),
            PGCTL_SERVICE_LOCK=str(lock),
        )
        if debug:
            env['PGCTL_DEBUG'] = 'true'
        else:
            env.pop('PGCTL_DEBUG', None)
        if logs:
            env.pop('PGCTL_SERVICE_PROCESS', None)
        else:
            env['PGCTL_SERVICE_PROCESS'] = 'true'
        return frozendict(env)
